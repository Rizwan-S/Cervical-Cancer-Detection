{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UHLt5h3o_nxlovqabq80QZ4wV1ggnjEh","authorship_tag":"ABX9TyO3zZfySS84tigOEM+4aXRu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNBy88yhfuHd","executionInfo":{"status":"ok","timestamp":1673685573109,"user_tz":-330,"elapsed":7153,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"958525fb-d626-4faa-b961-c91c2dce9d9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"]}],"source":["## importing required libraries\n","import os\n","import torch\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rWGdB5Tf-Hy","executionInfo":{"status":"ok","timestamp":1673685596423,"user_tz":-330,"elapsed":23398,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"072a5d83-37ab-49ae-a73a-d6feaf3de0a5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMcftneNkUBP","executionInfo":{"status":"ok","timestamp":1673685596425,"user_tz":-330,"elapsed":72,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"a597197b-7fa8-4bf6-c692-ee3cc6b98c13"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train_path_img   = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/train\"\n","train_path_label = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/labels/train\"\n","val_path_img     = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/val\"\n","val_path_label   = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/labels/val\"\n","test_path        = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/test\""],"metadata":{"id":"thz_XZ_2gDq5","executionInfo":{"status":"ok","timestamp":1673685596427,"user_tz":-330,"elapsed":58,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Clone YoloV6 Repo"],"metadata":{"id":"rsd94-regnRG"}},{"cell_type":"code","source":["!git clone https://github.com/meituan/YOLOv6.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GvwE7vDgd9K","executionInfo":{"status":"ok","timestamp":1673685597865,"user_tz":-330,"elapsed":1493,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"58599c28-f9e9-4e6d-8311-da18e54a354d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'YOLOv6'...\n","remote: Enumerating objects: 2671, done.\u001b[K\n","remote: Counting objects: 100% (131/131), done.\u001b[K\n","remote: Compressing objects: 100% (67/67), done.\u001b[K\n","remote: Total 2671 (delta 70), reused 102 (delta 64), pack-reused 2540\u001b[K\n","Receiving objects: 100% (2671/2671), 34.11 MiB | 44.27 MiB/s, done.\n","Resolving deltas: 100% (1476/1476), done.\n"]}]},{"cell_type":"code","source":["%cd YOLOv6\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BshfEp6igti4","executionInfo":{"status":"ok","timestamp":1673685597866,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"a0ad31c7-178d-4096-d934-916d1ff38d88"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/YOLOv6\n","/content/YOLOv6\n"]}]},{"cell_type":"code","source":["#Install all requirements\n","%pip install -r requirements.txt "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PMqsuF0g4Hv","executionInfo":{"status":"ok","timestamp":1673685605274,"user_tz":-330,"elapsed":7417,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"7470c650-8dd1-44e0-e9fc-6d886052d0e2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.13.0+cu116)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.14.0+cu116)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (4.64.1)\n","Collecting addict>=2.4.0\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (2.9.1)\n","Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (2.0.6)\n","Collecting onnx>=1.10.0\n","  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx-simplifier>=0.3.6\n","  Downloading onnx_simplifier-0.4.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.25.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.51.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.38.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.15.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.2.2)\n","Collecting onnx>=1.10.0\n","  Downloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rich\n","  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.2.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (6.0.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.12.7)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n","Installing collected packages: commonmark, addict, rich, onnx, thop, onnx-simplifier\n","Successfully installed addict-2.4.0 commonmark-0.9.1 onnx-1.12.0 onnx-simplifier-0.4.13 rich-13.0.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["# %cp -r \"/content/drive/MyDrive/Cervix Cytology Project/YoloV6/custom_dataset\" \"/content/YOLOv6\""],"metadata":{"id":"mr_t9VimiL0K","executionInfo":{"status":"ok","timestamp":1673685605276,"user_tz":-330,"elapsed":100,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Download Pretrained Weights"],"metadata":{"id":"rHWHWpE0oMjE"}},{"cell_type":"code","source":["# !wget https://github.com/meituan/YOLOv6/releases/download/0.2.0/yolov6n6.pt\n","!wget https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6n6.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zup9KbtToOjQ","outputId":"58bc6d81-4a08-4886-c895-b4e009345e0d","executionInfo":{"status":"ok","timestamp":1673685606424,"user_tz":-330,"elapsed":1246,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-14 08:40:04--  https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6n6.pt\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/0577c33f-e912-46ff-90b2-134bb2e5ef6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T084004Z&X-Amz-Expires=300&X-Amz-Signature=50145a57fbd814e1ab1d224e10db8e2d5e93cb122874bca8d9a8bce2bc11dd5b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6n6.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-01-14 08:40:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/0577c33f-e912-46ff-90b2-134bb2e5ef6c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T084004Z&X-Amz-Expires=300&X-Amz-Signature=50145a57fbd814e1ab1d224e10db8e2d5e93cb122874bca8d9a8bce2bc11dd5b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6n6.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22969979 (22M) [application/octet-stream]\n","Saving to: ‘yolov6n6.pt’\n","\n","yolov6n6.pt         100%[===================>]  21.91M  38.5MB/s    in 0.6s    \n","\n","2023-01-14 08:40:05 (38.5 MB/s) - ‘yolov6n6.pt’ saved [22969979/22969979]\n","\n"]}]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"-mNHa5GkjZjh"}},{"cell_type":"code","source":["!python tools/train.py --batch 8 --epochs 100 --conf configs/yolov6n6_finetune.py --data data/data.yaml --device 0"],"metadata":{"id":"zW8K5nZ0iVpI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673687936459,"user_tz":-330,"elapsed":2167642,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"934c4d34-8ca0-4787-9c9d-c10e90f36402"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Using 1 GPU for training... \n","training args are: Namespace(batch_size=8, bs_per_gpu=32, calib=False, check_images=False, check_labels=False, conf_file='configs/yolov6n6_finetune.py', data_path='data/data.yaml', device='0', dist_url='env://', distill=False, distill_feat=False, epochs=100, eval_final_only=False, eval_interval=20, fuse_ab=False, gpu_count=0, heavy_eval_range=50, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', quant=False, rank=-1, resume=False, save_ckpt_on_last_n_epoch=-1, save_dir='runs/train/exp2', stop_aug_last_n_epoch=15, teacher_model_path=None, temperature=20, workers=8, world_size=1, write_trainbatch_tb=False)\n","\n","Train: Final numbers of valid images: 300/ labels: 300. \n","0.1s for dataset initialization.\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 14500.12it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","0.1s for dataset initialization.\n","Loading state_dict from weights/yolov6n6.pt for fine-tuning...\n","Model: Model(\n","  (backbone): EfficientRep6(\n","    (stem): RepVGGBlock(\n","      (nonlinearity): ReLU(inplace=True)\n","      (se): Identity()\n","      (rbr_dense): Sequential(\n","        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","      (rbr_1x1): Sequential(\n","        (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (ERBlock_2): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_3): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_4): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (4): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_5): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_6): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (2): SimCSPSPPF(\n","        (cv1): SimConv(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv2): SimConv(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv3): SimConv(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv4): SimConv(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","        (cv5): SimConv(\n","          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv6): SimConv(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv7): SimConv(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","  )\n","  (neck): RepBiFPANNeck6(\n","    (reduce_layer0): SimConv(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion0): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p5): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer1): SimConv(\n","      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion1): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer2): SimConv(\n","      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion2): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample2): SimConv(\n","      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample1): SimConv(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n5): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample0): SimConv(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n6): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (detect): Detect(\n","    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (stems): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (reg_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_preds): ModuleList(\n","      (0): Conv2d(32, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(128, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (3): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_preds): ModuleList(\n","      (0): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (3): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","2023-01-14 08:42:54.193377: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Training start...\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","  0% 0/38 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","      0/99     1.711         0     1.599: 100% 38/38 [00:21<00:00,  1.78it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:00<00:00, 13.75it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Epoch: 0 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      1/99     1.668         0     1.511: 100% 38/38 [00:11<00:00,  3.30it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      2/99     1.619         0     1.451: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      3/99     1.556         0     1.443: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      4/99     1.246         0     1.212: 100% 38/38 [00:11<00:00,  3.18it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      5/99     1.218         0     1.204: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      6/99       1.2         0     1.196: 100% 38/38 [00:11<00:00,  3.26it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      7/99     1.202         0     1.175: 100% 38/38 [00:12<00:00,  3.10it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      8/99     1.183         0     1.164: 100% 38/38 [00:12<00:00,  3.08it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      9/99     1.143         0     1.161: 100% 38/38 [00:11<00:00,  3.22it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     10/99     1.116         0     1.157: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     11/99     1.095         0     1.147: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     12/99     1.056         0     1.161: 100% 38/38 [00:12<00:00,  3.06it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     13/99     1.019         0     1.164: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     14/99    0.9881         0     1.151: 100% 38/38 [00:11<00:00,  3.26it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     15/99    0.9729         0     1.149: 100% 38/38 [00:11<00:00,  3.18it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     16/99    0.9147         0     1.153: 100% 38/38 [00:10<00:00,  3.52it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     17/99    0.8826         0     1.154: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     18/99      0.86         0     1.158: 100% 38/38 [00:11<00:00,  3.44it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     19/99    0.8248         0     1.154: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     20/99    0.8023         0     1.133: 100% 38/38 [00:11<00:00,  3.24it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:03<00:00,  1.17it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.23s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.10s).\n","Accumulating evaluation results...\n","DONE (t=0.07s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.046\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.063\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129\n","Results saved to runs/train/exp2\n","Epoch: 20 | mAP@0.5: 0.04585002305256113 | mAP@0.50:0.95: 0.01582555056960277\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     21/99    0.7682         0     1.149: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     22/99    0.7699         0     1.144: 100% 38/38 [00:11<00:00,  3.44it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     23/99    0.7247         0     1.137: 100% 38/38 [00:10<00:00,  3.48it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     24/99    0.7262         0     1.126: 100% 38/38 [00:12<00:00,  3.15it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     25/99    0.7121         0     1.147: 100% 38/38 [00:11<00:00,  3.34it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     26/99    0.6961         0     1.127: 100% 38/38 [00:11<00:00,  3.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     27/99    0.6936         0     1.112: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     28/99    0.6796         0     1.093: 100% 38/38 [00:11<00:00,  3.27it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     29/99    0.6701         0     1.097: 100% 38/38 [00:12<00:00,  3.09it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     30/99    0.6882         0     1.098: 100% 38/38 [00:11<00:00,  3.26it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     31/99    0.6673         0     1.101: 100% 38/38 [00:12<00:00,  3.07it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     32/99    0.6526         0     1.086: 100% 38/38 [00:11<00:00,  3.24it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     33/99    0.6665         0     1.082: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     34/99    0.6461         0     1.077: 100% 38/38 [00:11<00:00,  3.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     35/99    0.6511         0     1.065: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     36/99    0.6489         0     1.073: 100% 38/38 [00:11<00:00,  3.19it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     37/99    0.6618         0     1.059: 100% 38/38 [00:11<00:00,  3.19it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     38/99    0.6275         0     1.065: 100% 38/38 [00:11<00:00,  3.17it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     39/99    0.6497         0     1.065: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     40/99    0.6204         0      1.06: 100% 38/38 [00:11<00:00,  3.41it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.89it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.25s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.05s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.169\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n","Results saved to runs/train/exp2\n","Epoch: 40 | mAP@0.5: 0.23021293073572519 | mAP@0.50:0.95: 0.10228799232011852\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     41/99    0.6343         0     1.048: 100% 38/38 [00:11<00:00,  3.30it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     42/99    0.6234         0     1.045: 100% 38/38 [00:11<00:00,  3.27it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     43/99    0.6232         0     1.044: 100% 38/38 [00:11<00:00,  3.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     44/99    0.6113         0     1.064: 100% 38/38 [00:11<00:00,  3.39it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     45/99    0.6298         0     1.048: 100% 38/38 [00:11<00:00,  3.39it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     46/99     0.629         0     1.035: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     47/99    0.6147         0     1.038: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     48/99    0.5909         0     1.042: 100% 38/38 [00:10<00:00,  3.59it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     49/99    0.6279         0     1.035: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     50/99    0.6219         0     1.029: 100% 38/38 [00:11<00:00,  3.23it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     51/99    0.6302         0     1.021: 100% 38/38 [00:11<00:00,  3.17it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.84it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.08s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.99s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.272\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.193\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n","Results saved to runs/train/exp2\n","Epoch: 51 | mAP@0.5: 0.27156393413556995 | mAP@0.50:0.95: 0.12454882827007298\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     52/99    0.6101         0     1.043: 100% 38/38 [00:11<00:00,  3.40it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     53/99    0.6068         0     1.032: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     54/99    0.5872         0     1.009: 100% 38/38 [00:11<00:00,  3.40it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.68it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.05s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.42s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.264\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.194\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n","Results saved to runs/train/exp2\n","Epoch: 54 | mAP@0.5: 0.2637340574775177 | mAP@0.50:0.95: 0.1223757631748149\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     55/99    0.6201         0     1.038: 100% 38/38 [00:10<00:00,  3.55it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     56/99    0.5967         0      1.03: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     57/99    0.6126         0     1.033: 100% 38/38 [00:11<00:00,  3.28it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.91it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.34s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.301\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n","Results saved to runs/train/exp2\n","Epoch: 57 | mAP@0.5: 0.3005248855514467 | mAP@0.50:0.95: 0.1469697449634418\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     58/99    0.6056         0      1.03: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     59/99    0.6012         0     1.024: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     60/99    0.5971         0     1.017: 100% 38/38 [00:11<00:00,  3.37it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  2.00it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.24s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.16s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n","Results saved to runs/train/exp2\n","Epoch: 60 | mAP@0.5: 0.31739213480293293 | mAP@0.50:0.95: 0.14820797266911073\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     61/99    0.6169         0     1.021: 100% 38/38 [00:11<00:00,  3.43it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     62/99    0.6004         0     1.011: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     63/99    0.6023         0     1.009: 100% 38/38 [00:10<00:00,  3.58it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.01it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.26s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.32s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438\n","Results saved to runs/train/exp2\n","Epoch: 63 | mAP@0.5: 0.3299872232799932 | mAP@0.50:0.95: 0.15986533683319643\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     64/99    0.5927         0     1.008: 100% 38/38 [00:12<00:00,  3.15it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     65/99    0.5943         0     1.022: 100% 38/38 [00:11<00:00,  3.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     66/99    0.5982         0     1.018: 100% 38/38 [00:11<00:00,  3.36it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.96it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.37s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n","Results saved to runs/train/exp2\n","Epoch: 66 | mAP@0.5: 0.3231152509112553 | mAP@0.50:0.95: 0.15949230495597794\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     67/99    0.5945         0      1.01: 100% 38/38 [00:11<00:00,  3.21it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     68/99    0.6067         0     1.008: 100% 38/38 [00:11<00:00,  3.30it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     69/99    0.5853         0    0.9874: 100% 38/38 [00:11<00:00,  3.23it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.97it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.99s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.214\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.435\n","Results saved to runs/train/exp2\n","Epoch: 69 | mAP@0.5: 0.3328374322696027 | mAP@0.50:0.95: 0.15802174558080176\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     70/99    0.5947         0     1.008: 100% 38/38 [00:11<00:00,  3.41it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     71/99    0.6075         0     1.001: 100% 38/38 [00:11<00:00,  3.34it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     72/99    0.5968         0    0.9994: 100% 38/38 [00:11<00:00,  3.31it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.06it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.26s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.31s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n","Results saved to runs/train/exp2\n","Epoch: 72 | mAP@0.5: 0.3435483056160456 | mAP@0.50:0.95: 0.1722886271070268\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     73/99    0.5878         0     1.012: 100% 38/38 [00:11<00:00,  3.19it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     74/99    0.5846         0     1.003: 100% 38/38 [00:12<00:00,  3.08it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     75/99    0.5951         0      1.02: 100% 38/38 [00:11<00:00,  3.40it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.02it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.25s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.34s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n","Results saved to runs/train/exp2\n","Epoch: 75 | mAP@0.5: 0.3295766774789654 | mAP@0.50:0.95: 0.16398588108172152\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     76/99    0.5853         0     1.023: 100% 38/38 [00:11<00:00,  3.18it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     77/99    0.5967         0     1.017: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     78/99    0.6101         0     1.012: 100% 38/38 [00:11<00:00,  3.37it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.04it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.17s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.237\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n","Results saved to runs/train/exp2\n","Epoch: 78 | mAP@0.5: 0.3421384403370598 | mAP@0.50:0.95: 0.17790080175136644\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     79/99    0.5895         0    0.9975: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     80/99     0.571         0     1.002: 100% 38/38 [00:12<00:00,  3.06it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     81/99    0.5839         0     1.003: 100% 38/38 [00:11<00:00,  3.44it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.07it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.25s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.21s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n","Results saved to runs/train/exp2\n","Epoch: 81 | mAP@0.5: 0.3473443910986968 | mAP@0.50:0.95: 0.18620578281071334\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     82/99    0.6007         0     1.001: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     83/99    0.5818         0     0.996: 100% 38/38 [00:10<00:00,  3.58it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     84/99    0.5933         0    0.9839: 100% 38/38 [00:11<00:00,  3.22it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.03it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.22s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.23s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.138\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.227\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n","Results saved to runs/train/exp2\n","Epoch: 84 | mAP@0.5: 0.34239203362982046 | mAP@0.50:0.95: 0.16822144758747382\n","Train: Final numbers of valid images: 300/ labels: 300. \n","0.6s for dataset initialization.\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 12212.63it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","0.2s for dataset initialization.\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     85/99    0.5252         0     1.018: 100% 38/38 [00:07<00:00,  5.14it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     86/99    0.5063         0      1.01: 100% 38/38 [00:06<00:00,  6.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     87/99    0.5088         0    0.9974: 100% 38/38 [00:06<00:00,  6.10it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.42it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.20s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.75s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.360\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.233\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n","Results saved to runs/train/exp2\n","Epoch: 87 | mAP@0.5: 0.36028994055087094 | mAP@0.50:0.95: 0.19288468069119794\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     88/99    0.4975         0    0.9974: 100% 38/38 [00:06<00:00,  6.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     89/99    0.5047         0    0.9996: 100% 38/38 [00:06<00:00,  6.24it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     90/99    0.4915         0     0.997: 100% 38/38 [00:06<00:00,  6.32it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.46it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.18s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.75s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n","Results saved to runs/train/exp2\n","Epoch: 90 | mAP@0.5: 0.35193843917803247 | mAP@0.50:0.95: 0.18899919844633717\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     91/99    0.4942         0    0.9888: 100% 38/38 [00:06<00:00,  6.33it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     92/99    0.4835         0    0.9877: 100% 38/38 [00:06<00:00,  6.30it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     93/99     0.493         0    0.9769: 100% 38/38 [00:06<00:00,  6.25it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.52it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.15s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.04s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.77s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.238\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n","Results saved to runs/train/exp2\n","Epoch: 93 | mAP@0.5: 0.36082276785237133 | mAP@0.50:0.95: 0.19443052284247833\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     94/99    0.4805         0    0.9744: 100% 38/38 [00:06<00:00,  6.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     95/99    0.4891         0    0.9723: 100% 38/38 [00:06<00:00,  6.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     96/99    0.4959         0    0.9814: 100% 38/38 [00:06<00:00,  6.20it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.41it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.04s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.76s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n","Results saved to runs/train/exp2\n","Epoch: 96 | mAP@0.5: 0.3714740575953609 | mAP@0.50:0.95: 0.20575154918716584\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     97/99    0.4885         0    0.9692: 100% 38/38 [00:06<00:00,  6.33it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     98/99    0.4868         0    0.9802: 100% 38/38 [00:06<00:00,  6.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     99/99    0.4951         0    0.9766: 100% 38/38 [00:06<00:00,  6.29it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.57it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.19s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.77s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.195\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n","Results saved to runs/train/exp2\n","Epoch: 99 | mAP@0.5: 0.36945024832311074 | mAP@0.50:0.95: 0.20208296246218466\n","\n","Training completed in 0.598 hours.\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"4oby-bdMlhFD"}},{"cell_type":"code","source":["!python tools/eval.py --data data/data.yaml --weights /content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt --device 0"],"metadata":{"id":"3qpvI3A4Oy17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673688022699,"user_tz":-330,"elapsed":16675,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"a795ef14-8a62-43ec-d9fa-70f53405acde"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=32, conf_thres=0.03, config_file='', data='data/data.yaml', device='0', do_coco_metric=True, do_pr_metric=False, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=False, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=False, name='exp', not_infer_on_rect=False, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', scale_exact=False, task='val', test_load_size=640, verbose=False, weights='/content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt')\n","Loading checkpoint from /content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt\n","\n","Fusing model...\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Switch model to deploy modality.\n","Model Summary: Params: 10.34M, Gflops: 12.39\n","Val: Checking formats of labels with 8 process(es): \n","50 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 50/50 [00:00<00:00, 1617.66it/s]\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 9328.55it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","0.5s for dataset initialization.\n","Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.46s/it]\n","\n","Evaluating speed.\n","Average pre-process time: 0.11 ms\n","Average inference time: 1.24 ms\n","Average NMS time: 8.55 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.05s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.12s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.043\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n","Results saved to runs/val/exp1\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"9444KdznlijM"}},{"cell_type":"code","source":["!python tools/infer.py --weights /content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt --yaml data/data.yaml --source /content/drive/MyDrive/Cervix\\ Cytology\\ Project/custom_dataset/images/test --device 0"],"metadata":{"id":"SwV12j2fku9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673688291968,"user_tz":-330,"elapsed":52344,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"f6ddbef6-73bc-41d7-cff9-10cd3418abe8"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(agnostic_nms=False, classes=None, conf_thres=0.4, device='0', half=False, hide_conf=False, hide_labels=False, img_size=[640, 640], iou_thres=0.45, max_det=1000, name='exp', not_save_img=False, project='runs/inference', save_dir=None, save_txt=False, source='/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/test', view_img=False, weights='/content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt', yaml='data/data.yaml')\n","Save directory already existed\n","Loading checkpoint from /content/YOLOv6/runs/train/exp2/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","100% 50/50 [00:44<00:00,  1.11it/s]\n","Results saved to runs/inference/exp\n"]}]},{"cell_type":"markdown","source":["# Deply in ONNX Format"],"metadata":{"id":"KvmLtiItU-7H"}},{"cell_type":"code","source":["# !python deploy/ONNX/export_onnx.py --weights /content/YOLOv6/runs/train/exp/weights/best_ckpt.pt --device 0"],"metadata":{"id":"QBmqpxBtPUSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2119qiHiVFCc"},"execution_count":null,"outputs":[]}]}