{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UHLt5h3o_nxlovqabq80QZ4wV1ggnjEh","authorship_tag":"ABX9TyNOQrbqNTC4sc7gAQ3fXxtg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNBy88yhfuHd","executionInfo":{"status":"ok","timestamp":1673688712007,"user_tz":-330,"elapsed":5180,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"823cb4ad-c4e0-47c0-e535-0b65e6ddd0a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"]}],"source":["## importing required libraries\n","import os\n","import torch\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rWGdB5Tf-Hy","executionInfo":{"status":"ok","timestamp":1673688730996,"user_tz":-330,"elapsed":19024,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"30b55e76-2841-49cf-8141-0418f71db603"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMcftneNkUBP","executionInfo":{"status":"ok","timestamp":1673688730999,"user_tz":-330,"elapsed":56,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"1564d46b-f716-43c1-e8ad-2f1b7cf62bf4"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train_path_img   = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/train\"\n","train_path_label = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/labels/train\"\n","val_path_img     = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/val\"\n","val_path_label   = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/labels/val\"\n","test_path        = \"/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/test\""],"metadata":{"id":"thz_XZ_2gDq5","executionInfo":{"status":"ok","timestamp":1673688731000,"user_tz":-330,"elapsed":44,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Clone YoloV6 Repo"],"metadata":{"id":"rsd94-regnRG"}},{"cell_type":"code","source":["!git clone https://github.com/meituan/YOLOv6.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GvwE7vDgd9K","executionInfo":{"status":"ok","timestamp":1673688732387,"user_tz":-330,"elapsed":1430,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"4b34b5ee-4591-4c91-e252-f7cb15611925"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'YOLOv6'...\n","remote: Enumerating objects: 2671, done.\u001b[K\n","remote: Counting objects: 100% (131/131), done.\u001b[K\n","remote: Compressing objects: 100% (68/68), done.\u001b[K\n","remote: Total 2671 (delta 71), reused 100 (delta 63), pack-reused 2540\u001b[K\n","Receiving objects: 100% (2671/2671), 34.10 MiB | 43.27 MiB/s, done.\n","Resolving deltas: 100% (1478/1478), done.\n"]}]},{"cell_type":"code","source":["%cd YOLOv6\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BshfEp6igti4","executionInfo":{"status":"ok","timestamp":1673688732389,"user_tz":-330,"elapsed":27,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"7f4fa4b3-d3ad-450d-c305-efa7aed3fad9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/YOLOv6\n","/content/YOLOv6\n"]}]},{"cell_type":"code","source":["#Install all requirements\n","%pip install -r requirements.txt "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PMqsuF0g4Hv","executionInfo":{"status":"ok","timestamp":1673688739793,"user_tz":-330,"elapsed":7421,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"5a2911e0-a7e2-4ebd-fe82-2ba07529f5a4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.13.0+cu116)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.14.0+cu116)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (4.64.1)\n","Collecting addict>=2.4.0\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (2.9.1)\n","Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (2.0.6)\n","Collecting onnx>=1.10.0\n","  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx-simplifier>=0.3.6\n","  Downloading onnx_simplifier-0.4.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.25.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.4.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.38.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (57.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.51.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.19.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.2.2)\n","Collecting onnx>=1.10.0\n","  Downloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rich\n","  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.2.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (6.0.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.12.7)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n","Installing collected packages: commonmark, addict, rich, onnx, thop, onnx-simplifier\n","Successfully installed addict-2.4.0 commonmark-0.9.1 onnx-1.12.0 onnx-simplifier-0.4.13 rich-13.0.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["# %cp -r \"/content/drive/MyDrive/Cervix Cytology Project/YoloV6/custom_dataset\" \"/content/YOLOv6\""],"metadata":{"id":"mr_t9VimiL0K","executionInfo":{"status":"ok","timestamp":1673688739795,"user_tz":-330,"elapsed":51,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Download Pretrained Weights"],"metadata":{"id":"rHWHWpE0oMjE"}},{"cell_type":"code","source":["!wget https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6s6.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zup9KbtToOjQ","outputId":"cc541a44-4143-435a-fd35-33a55022e2f4","executionInfo":{"status":"ok","timestamp":1673688742231,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-14 09:32:20--  https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6s6.pt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/9d165183-ad27-4177-adec-a2a4cdfa42af?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T093220Z&X-Amz-Expires=300&X-Amz-Signature=f00941e3452c5d85403c08883bcac2d9c398261d998372e70ab462a53df52e48&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s6.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-01-14 09:32:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/9d165183-ad27-4177-adec-a2a4cdfa42af?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T093220Z&X-Amz-Expires=300&X-Amz-Signature=f00941e3452c5d85403c08883bcac2d9c398261d998372e70ab462a53df52e48&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s6.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 90164283 (86M) [application/octet-stream]\n","Saving to: ‘yolov6s6.pt’\n","\n","yolov6s6.pt         100%[===================>]  85.99M  91.7MB/s    in 0.9s    \n","\n","2023-01-14 09:32:22 (91.7 MB/s) - ‘yolov6s6.pt’ saved [90164283/90164283]\n","\n"]}]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"-mNHa5GkjZjh"}},{"cell_type":"code","source":["!python tools/train.py --batch 8 --epochs 100 --conf configs/yolov6s6_finetune.py --data data/data.yaml --device 0,1,2,3"],"metadata":{"id":"zW8K5nZ0iVpI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673691065455,"user_tz":-330,"elapsed":2250872,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"b02b6d36-a15f-434e-fda7-40c048507f11"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Using 4 GPU for training... \n","training args are: Namespace(batch_size=8, bs_per_gpu=32, calib=False, check_images=False, check_labels=False, conf_file='configs/yolov6s6_finetune.py', data_path='data/data.yaml', device='0,1,2,3', dist_url='env://', distill=False, distill_feat=False, epochs=100, eval_final_only=False, eval_interval=20, fuse_ab=False, gpu_count=0, heavy_eval_range=50, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', quant=False, rank=-1, resume=False, save_ckpt_on_last_n_epoch=-1, save_dir='runs/train/exp1', stop_aug_last_n_epoch=15, teacher_model_path=None, temperature=20, workers=8, world_size=1, write_trainbatch_tb=False)\n","\n","Train: Final numbers of valid images: 300/ labels: 300. \n","0.1s for dataset initialization.\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 10542.69it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","0.1s for dataset initialization.\n","Loading state_dict from weights/yolov6s6.pt for fine-tuning...\n","Model: Model(\n","  (backbone): EfficientRep6(\n","    (stem): RepVGGBlock(\n","      (nonlinearity): ReLU(inplace=True)\n","      (se): Identity()\n","      (rbr_dense): Sequential(\n","        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","      (rbr_1x1): Sequential(\n","        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (ERBlock_2): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_3): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_4): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (4): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_5): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_6): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (2): SimCSPSPPF(\n","        (cv1): SimConv(\n","          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv2): SimConv(\n","          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv3): SimConv(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv4): SimConv(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","        (cv5): SimConv(\n","          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv6): SimConv(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv7): SimConv(\n","          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","  )\n","  (neck): RepBiFPANNeck6(\n","    (reduce_layer0): SimConv(\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion0): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p5): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer1): SimConv(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion1): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer2): SimConv(\n","      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Bifusion2): BiFusion(\n","      (cv1): SimConv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv2): SimConv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (cv3): SimConv(\n","        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): SimConv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_p3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample2): SimConv(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample1): SimConv(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n5): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample0): SimConv(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (Rep_n6): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (detect): Detect(\n","    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (stems): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (reg_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (3): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_preds): ModuleList(\n","      (0): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n","      (3): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_preds): ModuleList(\n","      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (3): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","2023-01-14 09:33:39.664560: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Training start...\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","  0% 0/38 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","      0/99     1.652         0     1.623: 100% 38/38 [00:21<00:00,  1.78it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:00<00:00, 13.78it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Epoch: 0 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      1/99      1.63         0     1.496: 100% 38/38 [00:11<00:00,  3.23it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      2/99     1.575         0     1.446: 100% 38/38 [00:11<00:00,  3.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      3/99      1.53         0     1.428: 100% 38/38 [00:11<00:00,  3.24it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      4/99     1.185         0     1.255: 100% 38/38 [00:11<00:00,  3.19it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      5/99     1.152         0     1.245: 100% 38/38 [00:10<00:00,  3.58it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      6/99     1.118         0     1.245: 100% 38/38 [00:11<00:00,  3.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      7/99     1.109         0     1.224: 100% 38/38 [00:12<00:00,  3.12it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      8/99     1.056         0     1.223: 100% 38/38 [00:12<00:00,  3.13it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","      9/99    0.9977         0     1.231: 100% 38/38 [00:11<00:00,  3.21it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     10/99     0.943         0     1.236: 100% 38/38 [00:11<00:00,  3.40it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     11/99    0.8974         0     1.228: 100% 38/38 [00:11<00:00,  3.44it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     12/99    0.8474         0     1.239: 100% 38/38 [00:12<00:00,  3.02it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     13/99    0.7924         0     1.233: 100% 38/38 [00:10<00:00,  3.47it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     14/99    0.7704         0     1.212: 100% 38/38 [00:11<00:00,  3.26it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     15/99     0.763         0     1.195: 100% 38/38 [00:11<00:00,  3.23it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     16/99    0.7385         0     1.167: 100% 38/38 [00:10<00:00,  3.49it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     17/99    0.7168         0     1.172: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     18/99    0.7136         0     1.156: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     19/99    0.7039         0     1.144: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     20/99    0.6876         0     1.124: 100% 38/38 [00:11<00:00,  3.22it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:03<00:00,  1.05it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.23s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.16s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.109\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n","Results saved to runs/train/exp1\n","Epoch: 20 | mAP@0.5: 0.10917033254520943 | mAP@0.50:0.95: 0.04601169996968597\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     21/99    0.6928         0     1.139: 100% 38/38 [00:12<00:00,  3.13it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     22/99    0.6847         0     1.129: 100% 38/38 [00:11<00:00,  3.34it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     23/99    0.6441         0     1.106: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     24/99    0.6614         0     1.105: 100% 38/38 [00:12<00:00,  3.16it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     25/99    0.6606         0     1.118: 100% 38/38 [00:11<00:00,  3.40it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     26/99    0.6366         0     1.094: 100% 38/38 [00:11<00:00,  3.17it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     27/99    0.6309         0     1.077: 100% 38/38 [00:11<00:00,  3.44it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     28/99    0.6346         0     1.063: 100% 38/38 [00:11<00:00,  3.30it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     29/99     0.624         0     1.074: 100% 38/38 [00:12<00:00,  3.03it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     30/99     0.619         0     1.074: 100% 38/38 [00:11<00:00,  3.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     31/99    0.6018         0     1.074: 100% 38/38 [00:12<00:00,  3.10it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     32/99    0.6029         0     1.059: 100% 38/38 [00:11<00:00,  3.23it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     33/99    0.6203         0     1.055: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     34/99    0.5924         0     1.053: 100% 38/38 [00:11<00:00,  3.21it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     35/99      0.59         0     1.033: 100% 38/38 [00:11<00:00,  3.39it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     36/99    0.6005         0     1.046: 100% 38/38 [00:12<00:00,  3.11it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     37/99    0.6089         0     1.041: 100% 38/38 [00:12<00:00,  3.16it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     38/99    0.5713         0     1.037: 100% 38/38 [00:11<00:00,  3.23it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     39/99    0.5909         0     1.038: 100% 38/38 [00:11<00:00,  3.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     40/99    0.5668         0     1.025: 100% 38/38 [00:11<00:00,  3.38it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.86it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.28s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.12s).\n","Accumulating evaluation results...\n","DONE (t=0.09s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n","Results saved to runs/train/exp1\n","Epoch: 40 | mAP@0.5: 0.29165128832786924 | mAP@0.50:0.95: 0.14129673211373697\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     41/99    0.5751         0      1.02: 100% 38/38 [00:11<00:00,  3.38it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     42/99    0.5725         0     1.005: 100% 38/38 [00:11<00:00,  3.25it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     43/99    0.5707         0     1.018: 100% 38/38 [00:11<00:00,  3.35it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     44/99     0.559         0     1.029: 100% 38/38 [00:11<00:00,  3.27it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     45/99    0.5753         0     1.019: 100% 38/38 [00:11<00:00,  3.33it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     46/99    0.5747         0     1.014: 100% 38/38 [00:11<00:00,  3.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     47/99    0.5655         0     1.017: 100% 38/38 [00:11<00:00,  3.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     48/99    0.5394         0     1.007: 100% 38/38 [00:10<00:00,  3.57it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     49/99    0.5672         0     1.012: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     50/99    0.5678         0     1.006: 100% 38/38 [00:12<00:00,  3.10it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     51/99    0.5649         0     1.003: 100% 38/38 [00:12<00:00,  3.09it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.85it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.97s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431\n","Results saved to runs/train/exp1\n","Epoch: 51 | mAP@0.5: 0.31662467285727286 | mAP@0.50:0.95: 0.14378569171723155\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     52/99     0.551         0     1.012: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     53/99     0.553         0     1.003: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     54/99    0.5566         0    0.9921: 100% 38/38 [00:11<00:00,  3.38it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:02<00:00,  1.85it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.08s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.47s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507\n","Results saved to runs/train/exp1\n","Epoch: 54 | mAP@0.5: 0.3544919159030988 | mAP@0.50:0.95: 0.19068650985969382\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     55/99     0.563         0     1.012: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     56/99    0.5548         0     1.004: 100% 38/38 [00:11<00:00,  3.31it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     57/99    0.5622         0     1.011: 100% 38/38 [00:11<00:00,  3.30it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.09it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.06s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.23s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n","Results saved to runs/train/exp1\n","Epoch: 57 | mAP@0.5: 0.3415552554255641 | mAP@0.50:0.95: 0.18283631474467626\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     58/99    0.5519         0     1.008: 100% 38/38 [00:11<00:00,  3.45it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     59/99    0.5587         0    0.9949: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     60/99    0.5575         0    0.9945: 100% 38/38 [00:11<00:00,  3.37it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.03it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.28s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.12s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.132\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n","Results saved to runs/train/exp1\n","Epoch: 60 | mAP@0.5: 0.32582931806239335 | mAP@0.50:0.95: 0.13214365017651017\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     61/99    0.5583         0    0.9964: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     62/99    0.5598         0    0.9869: 100% 38/38 [00:11<00:00,  3.42it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     63/99    0.5477         0    0.9854: 100% 38/38 [00:10<00:00,  3.67it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.03it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.49s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n","Results saved to runs/train/exp1\n","Epoch: 63 | mAP@0.5: 0.34498435826021556 | mAP@0.50:0.95: 0.16482322308740596\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     64/99     0.541         0    0.9773: 100% 38/38 [00:11<00:00,  3.17it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     65/99    0.5495         0    0.9974: 100% 38/38 [00:11<00:00,  3.29it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     66/99    0.5456         0    0.9879: 100% 38/38 [00:11<00:00,  3.39it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.00it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.08s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.63s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.351\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n","Results saved to runs/train/exp1\n","Epoch: 66 | mAP@0.5: 0.35055766142337 | mAP@0.50:0.95: 0.16716455131210647\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     67/99    0.5459         0    0.9837: 100% 38/38 [00:12<00:00,  3.12it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     68/99    0.5569         0    0.9756: 100% 38/38 [00:11<00:00,  3.21it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     69/99    0.5359         0    0.9644: 100% 38/38 [00:11<00:00,  3.22it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.02it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.26s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.96s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.192\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n","Results saved to runs/train/exp1\n","Epoch: 69 | mAP@0.5: 0.3402707367984029 | mAP@0.50:0.95: 0.14424129160435062\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     70/99    0.5526         0    0.9715: 100% 38/38 [00:11<00:00,  3.36it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     71/99    0.5468         0    0.9707: 100% 38/38 [00:11<00:00,  3.32it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     72/99    0.5464         0    0.9754: 100% 38/38 [00:11<00:00,  3.22it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.07it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.26s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.18s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.360\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.158\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n","Results saved to runs/train/exp1\n","Epoch: 72 | mAP@0.5: 0.3603371157240367 | mAP@0.50:0.95: 0.1839263866900787\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     73/99    0.5344         0    0.9701: 100% 38/38 [00:11<00:00,  3.28it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     74/99    0.5362         0     0.974: 100% 38/38 [00:11<00:00,  3.17it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     75/99    0.5417         0    0.9897: 100% 38/38 [00:11<00:00,  3.30it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.10it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.28s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.26s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.040\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n","Results saved to runs/train/exp1\n","Epoch: 75 | mAP@0.5: 0.3716666133300023 | mAP@0.50:0.95: 0.19566497142422454\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     76/99    0.5385         0    0.9902: 100% 38/38 [00:11<00:00,  3.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     77/99    0.5375         0     0.985: 100% 38/38 [00:11<00:00,  3.19it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     78/99     0.555         0    0.9797: 100% 38/38 [00:11<00:00,  3.18it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.11it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.24s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.11s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.242\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n","Results saved to runs/train/exp1\n","Epoch: 78 | mAP@0.5: 0.36783742261416674 | mAP@0.50:0.95: 0.19035727343746592\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     79/99    0.5334         0    0.9655: 100% 38/38 [00:11<00:00,  3.37it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     80/99    0.5224         0    0.9671: 100% 38/38 [00:12<00:00,  3.14it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     81/99    0.5314         0    0.9748: 100% 38/38 [00:11<00:00,  3.27it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.06it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.27s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.27s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538\n","Results saved to runs/train/exp1\n","Epoch: 81 | mAP@0.5: 0.3817921856208658 | mAP@0.50:0.95: 0.21114375382852313\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     82/99    0.5412         0    0.9786: 100% 38/38 [00:11<00:00,  3.35it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     83/99    0.5327         0    0.9663: 100% 38/38 [00:10<00:00,  3.55it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     84/99    0.5431         0    0.9545: 100% 38/38 [00:12<00:00,  3.16it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.10it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.25s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.19s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.329\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n","Results saved to runs/train/exp1\n","Epoch: 84 | mAP@0.5: 0.37334861670260094 | mAP@0.50:0.95: 0.18609847995250772\n","Train: Final numbers of valid images: 300/ labels: 300. \n","0.6s for dataset initialization.\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 8253.25it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","0.2s for dataset initialization.\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     85/99    0.4954         0    0.9815: 100% 38/38 [00:07<00:00,  5.05it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     86/99    0.4766         0    0.9782: 100% 38/38 [00:06<00:00,  6.10it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     87/99    0.4781         0    0.9682: 100% 38/38 [00:06<00:00,  6.12it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.42it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.21s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.76s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n","Results saved to runs/train/exp1\n","Epoch: 87 | mAP@0.5: 0.3762638905917932 | mAP@0.50:0.95: 0.19415780326479756\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     88/99      0.46         0    0.9675: 100% 38/38 [00:06<00:00,  5.95it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     89/99    0.4584         0    0.9721: 100% 38/38 [00:06<00:00,  6.11it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     90/99    0.4653         0    0.9606: 100% 38/38 [00:06<00:00,  6.03it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.53it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.20s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.74s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551\n","Results saved to runs/train/exp1\n","Epoch: 90 | mAP@0.5: 0.38756562767277447 | mAP@0.50:0.95: 0.21204711717391547\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     91/99    0.4698         0     0.943: 100% 38/38 [00:06<00:00,  6.02it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     92/99    0.4584         0    0.9524: 100% 38/38 [00:06<00:00,  6.20it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     93/99    0.4515         0    0.9458: 100% 38/38 [00:06<00:00,  6.12it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.28it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.04s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.76s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n","Results saved to runs/train/exp1\n","Epoch: 93 | mAP@0.5: 0.3957044865760372 | mAP@0.50:0.95: 0.21763834268788643\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     94/99    0.4646         0    0.9509: 100% 38/38 [00:06<00:00,  6.08it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     95/99    0.4549         0    0.9546: 100% 38/38 [00:06<00:00,  6.15it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     96/99    0.4601         0    0.9515: 100% 38/38 [00:06<00:00,  6.11it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.54it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.04s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.77s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n","Results saved to runs/train/exp1\n","Epoch: 96 | mAP@0.5: 0.3904806629774559 | mAP@0.50:0.95: 0.22160943930594537\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     97/99    0.4641         0    0.9432: 100% 38/38 [00:06<00:00,  6.05it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     98/99    0.4578         0    0.9439: 100% 38/38 [00:06<00:00,  6.00it/s]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","     99/99    0.4486         0    0.9419: 100% 38/38 [00:06<00:00,  6.11it/s]\n","Inferencing model in train datasets.: 100% 4/4 [00:01<00:00,  2.56it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.21s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.76s).\n","Accumulating evaluation results...\n","DONE (t=0.10s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n","Results saved to runs/train/exp1\n","Epoch: 99 | mAP@0.5: 0.3913531570911356 | mAP@0.50:0.95: 0.21684919457587026\n","\n","Training completed in 0.621 hours.\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"4oby-bdMlhFD"}},{"cell_type":"code","source":["!python tools/eval.py --data data/data.yaml --weights /content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt --device 0"],"metadata":{"id":"3qpvI3A4Oy17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673691111330,"user_tz":-330,"elapsed":19108,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"e2093832-4b5b-4130-c29e-bdf1ad409dd8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=32, conf_thres=0.03, config_file='', data='data/data.yaml', device='0', do_coco_metric=True, do_pr_metric=False, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=False, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=False, name='exp', not_infer_on_rect=False, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', scale_exact=False, task='val', test_load_size=640, verbose=False, weights='/content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt')\n","Loading checkpoint from /content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt\n","\n","Fusing model...\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Switch model to deploy modality.\n","Model Summary: Params: 41.32M, Gflops: 49.38\n","Val: Checking formats of labels with 8 process(es): \n","50 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 50/50 [00:02<00:00, 24.03it/s]\n","Convert to COCO format\n","100% 50/50 [00:00<00:00, 9092.36it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Cervix Cytology Project/custom_dataset/annotations/instances_val.json\n","Val: Final numbers of valid images: 50/ labels: 50. \n","2.5s for dataset initialization.\n","Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.45s/it]\n","\n","Evaluating speed.\n","Average pre-process time: 0.12 ms\n","Average inference time: 1.49 ms\n","Average NMS time: 10.46 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.05s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.85s).\n","Accumulating evaluation results...\n","DONE (t=0.11s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.257\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n","Results saved to runs/val/exp\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"9444KdznlijM"}},{"cell_type":"code","source":["!python tools/infer.py --weights /content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt --yaml data/data.yaml --source /content/drive/MyDrive/Cervix\\ Cytology\\ Project/custom_dataset/images/test --device 0"],"metadata":{"id":"SwV12j2fku9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673691175084,"user_tz":-330,"elapsed":42728,"user":{"displayName":"Rizwan Shaikh","userId":"13848484654072944392"}},"outputId":"740c4681-a723-4c1c-f677-c9d9d8e5c444"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(agnostic_nms=False, classes=None, conf_thres=0.4, device='0', half=False, hide_conf=False, hide_labels=False, img_size=[640, 640], iou_thres=0.45, max_det=1000, name='exp', not_save_img=False, project='runs/inference', save_dir=None, save_txt=False, source='/content/drive/MyDrive/Cervix Cytology Project/custom_dataset/images/test', view_img=False, weights='/content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt', yaml='data/data.yaml')\n","Loading checkpoint from /content/YOLOv6/runs/train/exp1/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","100% 50/50 [00:34<00:00,  1.44it/s]\n","Results saved to runs/inference/exp\n"]}]},{"cell_type":"markdown","source":["# Deply in ONNX Format"],"metadata":{"id":"KvmLtiItU-7H"}},{"cell_type":"code","source":["# !python deploy/ONNX/export_onnx.py --weights /content/YOLOv6/runs/train/exp/weights/best_ckpt.pt --device 0"],"metadata":{"id":"QBmqpxBtPUSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2119qiHiVFCc"},"execution_count":null,"outputs":[]}]}